{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:23.488642Z",
     "start_time": "2021-07-23T04:19:21.854534Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import yaml\n",
    "from train import train\n",
    "from utils import AttrDict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:23.885144Z",
     "start_time": "2021-07-23T04:19:23.880564Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:24.119144Z",
     "start_time": "2021-07-23T04:19:24.112032Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_config(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf8\") as stream:\n",
    "        opt = yaml.safe_load(stream)\n",
    "    opt = AttrDict(opt)\n",
    "    if opt.lang_char == 'None':\n",
    "        characters = ''\n",
    "        for data in opt['select_data'].split('-'):\n",
    "            csv_path = os.path.join(opt['train_data'], data, 'labels.csv')\n",
    "            df = pd.read_csv(csv_path, sep='^([^,]+),', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n",
    "            all_char = ''.join(df['words'])\n",
    "            characters += ''.join(set(all_char))\n",
    "        characters = sorted(set(characters))\n",
    "        opt.character= ''.join(characters)\n",
    "    else:\n",
    "        opt.character = opt.number + opt.symbol + opt.lang_char\n",
    "    os.makedirs(f'./saved_models/{opt.experiment_name}', exist_ok=True)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:49:07.045060Z",
     "start_time": "2021-07-23T04:20:15.050992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: all_data\n",
      "opt.select_data: ['train']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    all_data\t dataset: train\n",
      "all_data/train\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Usecols do not match columns, columns expected but not found: ['words', 'filename']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\dsash\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:588\u001b[0m, in \u001b[0;36mPythonParser._handle_usecols\u001b[1;34m(self, columns, usecols_key, num_original_columns)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 588\u001b[0m     col_indices\u001b[39m.\u001b[39mappend(usecols_key\u001b[39m.\u001b[39mindex(col))\n\u001b[0;32m    589\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: 'words' is not in list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dsash\\Repository\\EasyOCR\\trainer\\trainer.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dsash/Repository/EasyOCR/trainer/trainer.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m opt \u001b[39m=\u001b[39m get_config(\u001b[39m\"\u001b[39m\u001b[39mconfig_files/custom_data_train.yaml\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dsash/Repository/EasyOCR/trainer/trainer.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train(opt, amp\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\dsash\\Repository\\EasyOCR\\trainer\\train.py:40\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(opt, show_number, amp)\u001b[0m\n\u001b[0;32m     38\u001b[0m opt\u001b[39m.\u001b[39mselect_data \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mselect_data\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     39\u001b[0m opt\u001b[39m.\u001b[39mbatch_ratio \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mbatch_ratio\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m train_dataset \u001b[39m=\u001b[39m Batch_Balanced_Dataset(opt)\n\u001b[0;32m     42\u001b[0m log \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./saved_models/\u001b[39m\u001b[39m{\u001b[39;00mopt\u001b[39m.\u001b[39mexperiment_name\u001b[39m}\u001b[39;00m\u001b[39m/log_dataset.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m AlignCollate_valid \u001b[39m=\u001b[39m AlignCollate(imgH\u001b[39m=\u001b[39mopt\u001b[39m.\u001b[39mimgH, imgW\u001b[39m=\u001b[39mopt\u001b[39m.\u001b[39mimgW, keep_ratio_with_pad\u001b[39m=\u001b[39mopt\u001b[39m.\u001b[39mPAD, contrast_adjust\u001b[39m=\u001b[39mopt\u001b[39m.\u001b[39mcontrast_adjust)\n",
      "File \u001b[1;32mc:\\Users\\dsash\\Repository\\EasyOCR\\trainer\\dataset.py:56\u001b[0m, in \u001b[0;36mBatch_Balanced_Dataset.__init__\u001b[1;34m(self, opt)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39mprint\u001b[39m(dashed_line)\n\u001b[0;32m     55\u001b[0m log\u001b[39m.\u001b[39mwrite(dashed_line \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m _dataset, _dataset_log \u001b[39m=\u001b[39m hierarchical_dataset(root\u001b[39m=\u001b[39mopt\u001b[39m.\u001b[39mtrain_data, opt\u001b[39m=\u001b[39mopt, select_data\u001b[39m=\u001b[39m[selected_d])\n\u001b[0;32m     57\u001b[0m total_number_dataset \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(_dataset)\n\u001b[0;32m     58\u001b[0m log\u001b[39m.\u001b[39mwrite(_dataset_log)\n",
      "File \u001b[1;32mc:\\Users\\dsash\\Repository\\EasyOCR\\trainer\\dataset.py:132\u001b[0m, in \u001b[0;36mhierarchical_dataset\u001b[1;34m(root, opt, select_data)\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39mif\u001b[39;00m select_flag:\n\u001b[1;32m--> 132\u001b[0m     dataset \u001b[39m=\u001b[39m OCRDataset(dirpath, opt)\n\u001b[0;32m    133\u001b[0m     sub_dataset_log \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39msub-directory:\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mrelpath(dirpath,\u001b[39m \u001b[39mroot)\u001b[39m}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m num samples: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(dataset)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    134\u001b[0m     \u001b[39mprint\u001b[39m(sub_dataset_log)\n",
      "File \u001b[1;32mc:\\Users\\dsash\\Repository\\EasyOCR\\trainer\\dataset.py:149\u001b[0m, in \u001b[0;36mOCRDataset.__init__\u001b[1;34m(self, root, opt)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt \u001b[39m=\u001b[39m opt\n\u001b[0;32m    148\u001b[0m \u001b[39mprint\u001b[39m(root)\n\u001b[1;32m--> 149\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root,\u001b[39m'\u001b[39m\u001b[39mlabels.csv\u001b[39m\u001b[39m'\u001b[39m), sep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m^([^,]+),\u001b[39m\u001b[39m'\u001b[39m, engine\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m'\u001b[39m, usecols\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwords\u001b[39m\u001b[39m'\u001b[39m], keep_default_na\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    150\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnSamples \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf)\n\u001b[0;32m    152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopt\u001b[39m.\u001b[39mdata_filtering_off:\n",
      "File \u001b[1;32mc:\\Users\\dsash\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dsash\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dsash\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\dsash\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\dsash\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\dsash\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1750\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1753\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n\u001b[0;32m   1754\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1755\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dsash\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:122\u001b[0m, in \u001b[0;36mPythonParser.__init__\u001b[1;34m(self, f, **kwds)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_col_indices: \u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    117\u001b[0m columns: \u001b[39mlist\u001b[39m[\u001b[39mlist\u001b[39m[Scalar \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m]]\n\u001b[0;32m    118\u001b[0m (\n\u001b[0;32m    119\u001b[0m     columns,\n\u001b[0;32m    120\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_original_columns,\n\u001b[0;32m    121\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols,\n\u001b[1;32m--> 122\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_infer_columns()\n\u001b[0;32m    124\u001b[0m \u001b[39m# Now self.columns has the set of columns that we will process.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39m# The original set is stored in self.original_columns.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[39m# error: Cannot determine type of 'index_names'\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns: \u001b[39mlist\u001b[39m[Hashable]\n",
      "File \u001b[1;32mc:\\Users\\dsash\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:520\u001b[0m, in \u001b[0;36mPythonParser._infer_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    518\u001b[0m             columns \u001b[39m=\u001b[39m [names]\n\u001b[0;32m    519\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 520\u001b[0m         columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_usecols(\n\u001b[0;32m    521\u001b[0m             columns, columns[\u001b[39m0\u001b[39m], num_original_columns\n\u001b[0;32m    522\u001b[0m         )\n\u001b[0;32m    523\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    524\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dsash\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\python_parser.py:590\u001b[0m, in \u001b[0;36mPythonParser._handle_usecols\u001b[1;34m(self, columns, usecols_key, num_original_columns)\u001b[0m\n\u001b[0;32m    588\u001b[0m         col_indices\u001b[39m.\u001b[39mappend(usecols_key\u001b[39m.\u001b[39mindex(col))\n\u001b[0;32m    589\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m--> 590\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_usecols_names(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39musecols, usecols_key)\n\u001b[0;32m    591\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    592\u001b[0m     col_indices\u001b[39m.\u001b[39mappend(col)\n",
      "File \u001b[1;32mc:\\Users\\dsash\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:917\u001b[0m, in \u001b[0;36mParserBase._validate_usecols_names\u001b[1;34m(self, usecols, names)\u001b[0m\n\u001b[0;32m    915\u001b[0m missing \u001b[39m=\u001b[39m [c \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m usecols \u001b[39mif\u001b[39;00m c \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m names]\n\u001b[0;32m    916\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(missing) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 917\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsecols do not match columns, columns expected but not found: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    919\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmissing\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    920\u001b[0m     )\n\u001b[0;32m    922\u001b[0m \u001b[39mreturn\u001b[39;00m usecols\n",
      "\u001b[1;31mValueError\u001b[0m: Usecols do not match columns, columns expected but not found: ['words', 'filename']"
     ]
    }
   ],
   "source": [
    "opt = get_config(\"config_files/custom_data_train.yaml\")\n",
    "train(opt, amp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
